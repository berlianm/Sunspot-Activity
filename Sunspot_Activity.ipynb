{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib"
      ],
      "metadata": {
        "id": "_6o8mu4gdB0J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "nM-Rq92qdDkR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrintMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            logs = {}\n",
        "        print(f'Epoch {epoch + 1}, Loss: {logs[\"loss\"]}, MAE: {logs[\"mae\"]}')"
      ],
      "metadata": {
        "id": "qxIzbjlCdUcB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sunspot():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sunspots.csv'\n",
        "    urllib.request.urlretrieve(data_url, 'sunspots.csv')\n",
        "\n",
        "    time_step = []\n",
        "    sunspots = []\n",
        "\n",
        "    with open('sunspots.csv') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        next(reader)\n",
        "        for row in reader:\n",
        "            sunspots.append(float(row[2]))\n",
        "            time_step.append(int(row[0]))\n",
        "\n",
        "    series = np.array(sunspots)\n",
        "\n",
        "\n",
        "    min_val = np.min(series)\n",
        "    max_val = np.max(series)\n",
        "    series -= min_val\n",
        "    series /= max_val\n",
        "    time = np.array(time_step)\n",
        "\n",
        "    split_time = 3000\n",
        "\n",
        "    time_train = time[:split_time]\n",
        "    x_train = series[:split_time]\n",
        "    time_valid = time[split_time:]\n",
        "    x_valid = series[split_time:]\n",
        "\n",
        "    window_size = 30\n",
        "    batch_size = 32\n",
        "    shuffle_buffer_size = 1000\n",
        "\n",
        "    train_set = windowed_dataset(x_train, window_size=window_size,\n",
        "                                 batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(10,\n",
        "                              input_shape=[None, 1],\n",
        "                              activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=['mae']\n",
        "                  )\n",
        "\n",
        "    model.fit(train_set,\n",
        "              epochs=50,\n",
        "              callbacks=[PrintMetricsCallback()])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "i1X5BeRcdK4H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    model = sunspot()\n",
        "    model.save(\"model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oiNeZzoc1K8",
        "outputId": "876c6dad-3d14-4f70-ee89-698586bc0361"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "     90/Unknown - 1s 5ms/step - loss: 0.0109 - mae: 0.0773Epoch 1, Loss: 0.010782803408801556, MAE: 0.07705117762088776\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0108 - mae: 0.0771\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.0057 - mae: 0.0577Epoch 2, Loss: 0.0056748767383396626, MAE: 0.057657621800899506\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0057 - mae: 0.0577\n",
            "Epoch 3/50\n",
            "79/93 [========================>.....] - ETA: 0s - loss: 0.0048 - mae: 0.0506Epoch 3, Loss: 0.004799753427505493, MAE: 0.05058525875210762\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0048 - mae: 0.0506\n",
            "Epoch 4/50\n",
            "92/93 [============================>.] - ETA: 0s - loss: 0.0047 - mae: 0.0491Epoch 4, Loss: 0.0046584815718233585, MAE: 0.04904642701148987\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0047 - mae: 0.0490\n",
            "Epoch 5/50\n",
            "90/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 5, Loss: 0.004643607884645462, MAE: 0.04870280995965004\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0487\n",
            "Epoch 6/50\n",
            "88/93 [===========================>..] - ETA: 0s - loss: 0.0047 - mae: 0.0486Epoch 6, Loss: 0.004644898232072592, MAE: 0.04866425320506096\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0487\n",
            "Epoch 7/50\n",
            "79/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0483Epoch 7, Loss: 0.004642261657863855, MAE: 0.04863710328936577\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 8/50\n",
            "89/93 [===========================>..] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 8, Loss: 0.004642942454665899, MAE: 0.0486731082201004\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0487\n",
            "Epoch 9/50\n",
            "92/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 9, Loss: 0.004641537554562092, MAE: 0.04865434765815735\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0487\n",
            "Epoch 10/50\n",
            "79/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 10, Loss: 0.00464243907481432, MAE: 0.04863296449184418\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 11/50\n",
            "83/93 [=========================>....] - ETA: 0s - loss: 0.0047 - mae: 0.0487Epoch 11, Loss: 0.004640908911824226, MAE: 0.048635032027959824\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 12/50\n",
            "84/93 [==========================>...] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 12, Loss: 0.004640673752874136, MAE: 0.04862190783023834\n",
            "93/93 [==============================] - 1s 9ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 13/50\n",
            "74/93 [======================>.......] - ETA: 0s - loss: 0.0047 - mae: 0.0485Epoch 13, Loss: 0.0046381717547774315, MAE: 0.048602357506752014\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 14/50\n",
            "76/93 [=======================>......] - ETA: 0s - loss: 0.0046 - mae: 0.0483Epoch 14, Loss: 0.0046363817527890205, MAE: 0.04862666502594948\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 15/50\n",
            "72/93 [======================>.......] - ETA: 0s - loss: 0.0047 - mae: 0.0485Epoch 15, Loss: 0.004634346812963486, MAE: 0.04861941188573837\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 16/50\n",
            "80/93 [========================>.....] - ETA: 0s - loss: 0.0047 - mae: 0.0488Epoch 16, Loss: 0.004633048549294472, MAE: 0.04861617088317871\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 17/50\n",
            "74/93 [======================>.......] - ETA: 0s - loss: 0.0046 - mae: 0.0483Epoch 17, Loss: 0.004627886228263378, MAE: 0.048587698489427567\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 18/50\n",
            "91/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 18, Loss: 0.00462999427691102, MAE: 0.048591479659080505\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 19/50\n",
            "74/93 [======================>.......] - ETA: 0s - loss: 0.0046 - mae: 0.0482Epoch 19, Loss: 0.0046246238052845, MAE: 0.04856012389063835\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 20/50\n",
            "91/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0487Epoch 20, Loss: 0.004624208901077509, MAE: 0.048600271344184875\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 21/50\n",
            "79/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 21, Loss: 0.00462579308077693, MAE: 0.048586439341306686\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 22/50\n",
            "82/93 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 22, Loss: 0.004626884125173092, MAE: 0.048634808510541916\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 23/50\n",
            "80/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 23, Loss: 0.004624620545655489, MAE: 0.04856708273291588\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 24/50\n",
            "78/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 24, Loss: 0.004622373264282942, MAE: 0.04859565198421478\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 25/50\n",
            "83/93 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 25, Loss: 0.004622355103492737, MAE: 0.04858645051717758\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 26/50\n",
            "78/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 26, Loss: 0.004618148319423199, MAE: 0.048571884632110596\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 27/50\n",
            "74/93 [======================>.......] - ETA: 0s - loss: 0.0046 - mae: 0.0483Epoch 27, Loss: 0.00462451484054327, MAE: 0.0485956184566021\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 28/50\n",
            "86/93 [==========================>...] - ETA: 0s - loss: 0.0046 - mae: 0.0487Epoch 28, Loss: 0.004617330618202686, MAE: 0.04860160872340202\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 29/50\n",
            "86/93 [==========================>...] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 29, Loss: 0.00462245661765337, MAE: 0.048569779843091965\n",
            "93/93 [==============================] - 1s 9ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 30/50\n",
            "85/93 [==========================>...] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 30, Loss: 0.0046166712418198586, MAE: 0.0485953725874424\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 31/50\n",
            "83/93 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 31, Loss: 0.00462019257247448, MAE: 0.04859428107738495\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 32/50\n",
            "92/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 32, Loss: 0.0046201362274587154, MAE: 0.048572808504104614\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 33/50\n",
            "74/93 [======================>.......] - ETA: 0s - loss: 0.0047 - mae: 0.0487Epoch 33, Loss: 0.004615610931068659, MAE: 0.04856981337070465\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 34/50\n",
            "82/93 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 34, Loss: 0.004622175358235836, MAE: 0.048594992607831955\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 35/50\n",
            "77/93 [=======================>......] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 35, Loss: 0.004611163400113583, MAE: 0.048561565577983856\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 36/50\n",
            "90/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0487Epoch 36, Loss: 0.0046173520386219025, MAE: 0.0485866479575634\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 37/50\n",
            "78/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 37, Loss: 0.004614845849573612, MAE: 0.048576924949884415\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 38/50\n",
            "75/93 [=======================>......] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 38, Loss: 0.004610595293343067, MAE: 0.04856473207473755\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 39/50\n",
            "90/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 39, Loss: 0.004611040931195021, MAE: 0.04856347292661667\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 40/50\n",
            "74/93 [======================>.......] - ETA: 0s - loss: 0.0047 - mae: 0.0486Epoch 40, Loss: 0.004617495462298393, MAE: 0.0485670380294323\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 41/50\n",
            "82/93 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0487Epoch 41, Loss: 0.0046118032187223434, MAE: 0.0485774427652359\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 42/50\n",
            "78/93 [========================>.....] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 42, Loss: 0.004606745205819607, MAE: 0.04851323738694191\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0485\n",
            "Epoch 43/50\n",
            "86/93 [==========================>...] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 43, Loss: 0.004608160350471735, MAE: 0.04853639006614685\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0485\n",
            "Epoch 44/50\n",
            "76/93 [=======================>......] - ETA: 0s - loss: 0.0046 - mae: 0.0486Epoch 44, Loss: 0.004611262120306492, MAE: 0.04856891930103302\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 45/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 45, Loss: 0.0046104746870696545, MAE: 0.048536475747823715\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0485\n",
            "Epoch 46/50\n",
            "89/93 [===========================>..] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 46, Loss: 0.004609361290931702, MAE: 0.0485592857003212\n",
            "93/93 [==============================] - 1s 9ms/step - loss: 0.0046 - mae: 0.0486\n",
            "Epoch 47/50\n",
            "91/93 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0485Epoch 47, Loss: 0.004605485592037439, MAE: 0.048499710857868195\n",
            "93/93 [==============================] - 1s 9ms/step - loss: 0.0046 - mae: 0.0485\n",
            "Epoch 48/50\n",
            "73/93 [======================>.......] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 48, Loss: 0.0046034082770347595, MAE: 0.048498742282390594\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0485\n",
            "Epoch 49/50\n",
            "83/93 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0484Epoch 49, Loss: 0.0045997672714293, MAE: 0.04850045591592789\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0485\n",
            "Epoch 50/50\n",
            "82/93 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0483Epoch 50, Loss: 0.004606933798640966, MAE: 0.048525143414735794\n",
            "93/93 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}